{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting display option to show all columns and values\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "leads = pd.read_csv(\"Leads.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the head of the dataframe itself, many columns have entries as 'Select'. It if the default value of any field. It is as goog as null. Thus replacing 'Select' with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads =leads.replace('Select',np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of missing values column wise\n",
    "round((leads.isna().sum() / len(leads.index)) * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate rows\n",
    "leads.duplicated().sum()\n",
    "# No duplicate entries found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data dictionary\n",
    "##### Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unnecessary and high misssing value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot for cities\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='City',data=leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot for Country\n",
    "plt.figure(figsize=(25,4))\n",
    "sns.countplot(x='Country',data=leads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cities we have most of the leads from Mumbai.We don't have ciity name for almost 2300 leads and cities other than Mumbai are not specified. \n",
    "For Country column 99% of the leads are from India and thus column has very less varianvce.\n",
    "Prospect id is unique number and will not help in model building.\n",
    "Thus dropping these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns and columns with more than 40% missing values\n",
    "# imputing columns with more than 40% missing values may create bias in the data\n",
    "# Thus removing columns with morathan 40% missing values\n",
    "leads=leads.drop(['Prospect ID','Country','City'],1)\n",
    "# columns with 40% missing values\n",
    "leads = leads.drop(['How did you hear about X Education','Asymmetrique Profile Score','Asymmetrique Activity Score',\n",
    "                    'Asymmetrique Profile Index','Asymmetrique Activity Index','Lead Quality',\n",
    "                   'Lead Profile'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with no variance i.e. same value in each eantry\n",
    "\n",
    "# I agree to pay the amount through cheque\n",
    "print(leads['I agree to pay the amount through cheque'].value_counts())\n",
    "#Update me on Supply Chain Content\n",
    "print(leads['Update me on Supply Chain Content'].value_counts())\n",
    "#Receive More Updates About Our Courses\n",
    "print(leads['Receive More Updates About Our Courses'].value_counts())\n",
    "# Magzine\n",
    "print(leads['Magazine'].value_counts())\n",
    "# Get updates on DM Content\n",
    "leads['Get updates on DM Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that are not adding value to the model or are redundant\n",
    "leads = leads.drop(['I agree to pay the amount through cheque','Update me on Supply Chain Content','Receive More Updates About Our Courses','Magazine','Get updates on DM Content'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The origin identifier with which the customer was identified to be a lead. Includes API, Landing Page Submission, etc.\n",
    "leads['Lead Origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have only one entry for 'Quick Add Form'. It will not of much help in prediction thus deleting row.\n",
    "leads=leads[leads['Lead Origin']!= 'Quick Add Form']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lead Source \n",
    "The source of the lead. Includes Google, Organic Search, Olark Chat, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.39 missing values\n",
    "# There are many categories with few entries. Treating them as 'Others'\n",
    "leads['Lead Source'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaceing categories with few entries as others\n",
    "leads['Lead Source'].replace(to_replace=['bing','Click2call','Press_Release','Social Media','Live Chat','Pay per Click Ads','welearnblog_Home','NC_EDM','WeLearn','blog','testone','youtubechannel'],value='Other',inplace=True)\n",
    "leads['Lead Source'].replace(to_replace='google',value='Google',inplace=True)\n",
    "# 0.39% missing values. Imputing it higly occuring category(mode)\n",
    "leads['Lead Source'].fillna(value='Google',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Activity & Last Notable Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Last Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.11% missing values\n",
    "leads['Last Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0% missing values\n",
    "leads['Last Notable Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Last Notable Activity' and 'Last Activity' have similar categories. Considering these columns are showing similar or redundant information. Dropping 'Last Activity' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.drop('Last Activity',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting 'unreachabel' and 'email bounced' in one category\n",
    "leads['Last Notable Activity'].replace(to_replace ='Email Bounced',value='Unreachable',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some categories have very less entries\n",
    "# deleting such categories\n",
    "activity = ['Modified','Email Opened','SMS Sent','Page Visited on Website','Olark Chat Conversation','Email Link Clicked','Unreachable','Had a Phone Conversation']\n",
    "leads = leads.loc[leads['Last Notable Activity'].isin(activity)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping Columns which will not help in model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop(['Search','Newspaper Article','X Education Forums','Newspaper','Digital Advertisement'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tags\n",
    "- Tags assigned to customers indicating the current status of the lead.\n",
    "- 36% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Tags'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total leads converted from each category\n",
    "leads.groupby(leads['Tags']).Converted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsed of value count of each category and total leads converted category wise\n",
    "# combinibg categories which depict similar information\n",
    "leads['Tags'].replace(to_replace=['In confusion whether part time or DLP','Lateral student','Approached upfront',  'opp hangup', 'Still Thinking',  'Lost to Others','Shall take in the next coming month','Interested in Next batch', 'Want to take admission but has financial problems', 'number not provided'], value='Others',inplace=True)\n",
    "leads['Tags'].replace(to_replace=['wrong number given','University not recognized','invalid number','Recognition issue (DEC approval)','Not doing further education','Diploma holder (Not Eligible)'], value='Not Interested',inplace=True)\n",
    "leads['Tags'].replace(to_replace='in touch with EINS',value = 'Lost to EINS',inplace=True)\n",
    "leads['Tags'].replace(to_replace='Interested  in full time MBA',value = 'Interested in other courses',inplace=True)\n",
    "leads['Tags'].replace(to_replace=['switched off','Busy'], value='Busy-switchoff',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Tags'].astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Tags'].fillna(value='Will revert after reading the email',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is your current occupation - 29% missing values\n",
    "# making col name shorter \n",
    "leads['occupation'] = leads['What is your current occupation']\n",
    "leads.drop('What is your current occupation',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countplot category wise\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='occupation',data=leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing 29% of missing values with mode\n",
    "leads['occupation'].fillna(value='Unemployed', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What matters most to you in choosing a course - 29% missing values\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='What matters most to you in choosing a course',data=leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Specialization'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Specialization' has 36% missing values. imputing 36% of data may create noise in the data. \n",
    "'What matters most to you in choosing a course' has 29% missing values. Also data is highly skewd category wise.Thus deleting this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = leads.drop(['Specialization','What matters most to you in choosing a course','Tags'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Total Visits & Total Time Spent on Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Total Visits'-The total number of visits made by the customer on the website.\n",
    "# 1.11% missing value\n",
    "sns.boxplot(leads['TotalVisits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "leads = leads[leads['TotalVisits']<=20]\n",
    "leads['TotalVisits'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As mean and median have same values. Imputing with median.\n",
    "leads['TotalVisits'].fillna(value=3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['Total Time Spent on Website'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Time Spent on Website\n",
    "sns.distplot(leads['Total Time Spent on Website'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While mean of the total time spend on the website is 0, we see the gradual increase in the total time spent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page views per visit \n",
    "sns.boxplot(leads['Page Views Per Visit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting numeric columns in one dataframe\n",
    "numeric_df = leads[['TotalVisits','Total Time Spent on Website','Page Views Per Visit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric columns\n",
    "numeric_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'TotalVisits', y = 'Page Views Per Visit', data=leads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see as total visits to the site increases the Page Views Per Visit also increases and have a correlation of 71% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that 'Page Views Per Visit' and TotatVisits are highly correlated. Thus dropping 'page per views'\n",
    "leads.drop('Page Views Per Visit',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads['A free copy of Mastering The Interview'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info of dataset after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting some binary variables (Yes/No) to 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to map\n",
    "\n",
    "varlist =  ['Do Not Email', 'Do Not Call', 'Through Recommendations', 'A free copy of Mastering The Interview']\n",
    "\n",
    "# Defining the map function\n",
    "def binary_map(x):\n",
    "    return x.map({'Yes': 1, \"No\": 0})\n",
    "\n",
    "# Applying the function \n",
    "leads[varlist] = leads[varlist].apply(binary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Dummy variable for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummines for multi-level categorical variable\n",
    "d1 = pd.get_dummies(leads['Lead Origin'],drop_first=True,prefix='Lead_Origin')\n",
    "d2 = pd.get_dummies(leads['Lead Source'],drop_first=True,prefix='Lead_Source')\n",
    "d3 = pd.get_dummies(leads['Last Notable Activity'],drop_first=True,prefix='LastActivity')\n",
    "d4 = pd.get_dummies(leads['occupation'],drop_first=True,prefix='occupation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concating created dummies\n",
    "leads = pd.concat([leads,d1,d2,d3,d4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing original columns\n",
    "leads.drop(['Lead Origin','Lead Source','Last Notable Activity','occupation'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Dataframe\n",
    "leads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the correlation matrix \n",
    "plt.figure(figsize = (20,10))        # Size of the figure\n",
    "sns.heatmap(leads.drop('Lead Number',1).corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Lead_Origin_LeadAddForm' is highly correlated with 'Lead_Source_Reference' (0.85 correlation)\n",
    "Thus dropping 'Lead_Origin_LeadAddForm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.drop(['Lead_Origin_Lead Add Form','Lead_Origin_Lead Import','Lead_Source_Olark Chat','LastActivity_Modified','occupation_Unemployed'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after outlier treatment and dropping missing values we came up with final clean dataset with 9002 rows\n",
    "leads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion rate\n",
    "leads['Converted'].sum() / len(leads.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting independent variables in X\n",
    "X = leads.drop(['Lead Number','Converted'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting dependent variable in y\n",
    "y = leads['Converted']\n",
    "Lead_Number = leads['Lead Number']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data in train-test\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[['TotalVisits','Total Time Spent on Website']] = scaler.fit_transform(X_train[['TotalVisits','Total Time Spent on Website']])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model using all features - Model1\n",
    "logm1 = sm.GLM(y_train, (sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using RFE\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 17)             # running RFE with 13 variables as output\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 - RFE 17 Features (X_train_sm)\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res2 = logm2.fit()\n",
    "res2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While VIF's seems to be in limit i.e. vif < 5. Some features have very high p-value.\n",
    "# Removing insignificant features p-value = 0.999\n",
    "col = col.drop('occupation_Housewife',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables - Model 3\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res3 = logm3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF- Model3\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insignificant variable - p-val = 0.999\n",
    "col = col.drop('LastActivity_Had a Phone Conversation',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables - Model 4\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res3 = logm3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF- Model4\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('LastActivity_Olark Chat Conversation',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables - Model 5\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res3 = logm3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF- Model5\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('occupation_Other',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables - Model 6\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res3 = logm3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF- Model6\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Source_Facebook',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables - Model 7\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res3 = logm3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF- Model7\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = col.drop('Lead_Source_Referral Sites',1)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-run the model using the selected variables - Model 8\n",
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\n",
    "res3 = logm3.fit()\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF- Model8\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = res3.predict(X_train_sm).values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\n",
    "y_train_pred_final['Lead_NUmber'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.sort_values(by='Converted_Prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking 0.4 as Cut-off probability \n",
    "y_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.4 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the ROC curve hugging the upper left corner i.e. curve with high True Positive Rate and low False Positive Rate. Higher the area under the curve better is the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Cutoff point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph taking 0.35 as optimum cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.35 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning 'Lead Score' to each 'Lead Number' \n",
    "y_train_pred_final['Lead Score'] = y_train_pred_final.Converted_Prob.map( lambda x: round(x*100,2))\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final['final_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got the accuracy as 79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted )\n",
    "confusion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "round((TP / float(TP+FN))*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have got 'Sensitivity' of 81%. This means outof total converted leads we are able to identify 81% leads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[['TotalVisits','Total Time Spent on Website']] = scaler.transform(X_test[['TotalVisits','Total Time Spent on Website']])\n",
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stats model, adding constant\n",
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = res3.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final = pd.DataFrame({'Converted':y_test.values, 'Converted_Prob':y_test_pred})\n",
    "y_test_pred_final['Lead_Number'] = y_test.index\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final['final_predicted'] = y_test_pred_final.Converted_Prob.map(lambda x: 1 if x>0.35 else 0)\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final['Lead Score'] = y_test_pred_final.Converted_Prob.map(lambda x: round(x*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the accuracy for test set\n",
    "metrics.accuracy_score(y_test_pred_final.Converted, y_test_pred_final.final_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 77% of accuracy in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test set\n",
    "confusion_test = metrics.confusion_matrix(y_test_pred_final.Converted, y_test_pred_final.final_predicted )\n",
    "confusion_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation matrics for test set\n",
    "TP = confusion2[1,1] # true positive \n",
    "TN = confusion2[0,0] # true negatives\n",
    "FP = confusion2[0,1] # false positives\n",
    "FN = confusion2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model we got 81% accuracy on the test set as well. That means out of total leads converted our model is able to predict 81% leads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got specificity of the model to be 78%. That means total leads that are not converted (0) we are able to identify 78% of the leads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=y_train_pred_final[['Lead_NUmber','Converted','final_predicted','Lead Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test =y_test_pred_final[['Lead_NUmber','Converted','final_predicted','Lead Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Dataframe of Lead_Number with Lead Score assigned to it\n",
    "LeadNumber_wt_LeadScore = pd.concat([Y_train,Y_test])\n",
    "LeadNumber_wt_LeadScore.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeadNumber_wt_LeadScore.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We came up with final model with:\n",
    "- Accuracy : 77% \n",
    "- Sensitivity : 81%\n",
    "- Specificity : 78%\n",
    "\n",
    "for the test dataset. \n",
    "*We got the similar values for training dataset as well\n",
    "\n",
    "As we need to maximise the conversion rate of the leads, i.e. identifying potential lead accurately we need to have sensitivity more than specificity. So that we do not loose on potential lead.\n",
    "\n",
    "We have assigned 'Lead Score' to each Lead. And identified leads with score more than 35% as hot leads or potential leads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ****************************************************************************************************************************\n",
    "#### ****************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question 3\n",
    "We can achieve this by increasing TPR i.e. True Positive Rate\n",
    "TPR = Predicted positves / Actual Positives. That is predicting almost all the positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['predicted_Q3'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.2 else 0)\n",
    "\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for 0.2 as cutoff\n",
    "confusion_Q3 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted_Q3 )\n",
    "confusion_Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation matrics \n",
    "TP = confusion_Q3[1,1] # true positive \n",
    "TN = confusion_Q3[0,0] # true negatives\n",
    "FP = confusion_Q3[0,1] # false positives\n",
    "FN = confusion_Q3[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_Positive_Rate = TP / (FN + TP)\n",
    "print(\"True Positive Rate:\", True_Positive_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "hot_leads = y_train_pred_final.sort_values(by='Lead Score', ascending=False).head(20)\n",
    "hot_leads[['Lead_NUmber','Converted','final_predicted','Lead Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['predicted_Q4'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.97 else 0)\n",
    "\n",
    "y_train_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for improving precision\n",
    "confusion_Q4 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted_Q3 )\n",
    "confusion_Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation matrics \n",
    "TP = confusion_Q4[1,1] # true positive \n",
    "TN = confusion_Q4[0,0] # true negatives\n",
    "FP = confusion_Q4[0,1] # false positives\n",
    "FN = confusion_Q4[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
